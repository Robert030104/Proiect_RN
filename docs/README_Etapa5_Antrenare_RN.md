# ğŸ“˜ README â€“ Etapa 5: Configurarea È™i Antrenarea Modelului RN

**Disciplina:** ReÈ›ele Neuronale  
**InstituÈ›ie:** POLITEHNICA BucureÈ™ti â€“ FIIR  
**Student:** Pintea Robert Stefan  
**Link Repository GitHub:** https://github.com/Robert030104/Proiect_RN  
**Data:** 19/12/2025  

Data predÄƒrii: 12.02.2026

# Scopul Etapei 5

AceastÄƒ etapÄƒ corespunde punctului 6. Configurarea È™i antrenarea modelului RN din lista de 9 etape.

# Obiectiv principal

Antrenarea efectivÄƒ a modelului RN (MLP PyTorch) pentru predicÈ›ia defectelor auto pe date OBD-like simulate realist, evaluarea performanÈ›ei pe setul de test È™i integrarea modelului antrenat Ã®n aplicaÈ›ia Streamlit.

# PREREQUISITE â€“ Verificare Etapa 4 (ÃNDEPLINIT)

âœ” State Machine definit È™i documentat
âœ” ContribuÈ›ie â‰¥40% date originale (dataset generat Ã®n dataset.py)
âœ” Modul Data Logging funcÈ›ional (genereazÄƒ CSV raw)
âœ” Modul RN definit (MLP PyTorch)
âœ” UI Streamlit funcÈ›ional (iniÈ›ial cu model dummy)

# PregÄƒtire Date pentru Antrenare

# Pipeline complet rulat:

py src/data_acquisition/dataset.py
py src/preprocesing/procesare_dataset.py
py src/preprocesing/split.py

Split realizat:

70% Train (8400 samples)

15% Validation (1800 samples)

15% Test (1800 samples)

random_state = 42

stratificat pe variabila defect

Defect rate final dataset: â‰ˆ 23%

Nivel 1 â€“ Obligatoriu
âœ” Antrenare Model

Model: MLP PyTorch

Antrenat cu:

py src/neural_network/train_model.py


Model salvat Ã®n:

models/trained_model.pt

âœ” Hiperparametri FolosiÈ›i
Hiperparametru	Valoare AleasÄƒ	Justificare
Learning rate	0.001	Valoare stabilÄƒ pentru Adam, convergenÈ›Äƒ rapidÄƒ
Batch size	32	Echilibru Ã®ntre stabilitate gradient È™i timp antrenare
Epochs	50 (early stopping activ)	Permite convergenÈ›Äƒ fÄƒrÄƒ overfitting
Optimizer	Adam	Adaptive learning rate, potrivit pentru MLP
Loss	BCEWithLogitsLoss	Clasificare binarÄƒ
Activation	ReLU (hidden) + Sigmoid (output implicit)	ReLU pentru non-linearitate, Sigmoid pentru probabilitate
Justificare Batch Size

Avem 8400 samples train â†’ 8400 / 32 â‰ˆ 262 batch-uri / epocÄƒ.
Batch 32 oferÄƒ:

gradient stabil

timp de antrenare rezonabil

memorie RAM sigurÄƒ pe CPU

Evaluare pe Test Set

Rulat cu:

py src/neural_network/evaluare_model.py

Rezultate finale (Test Set)

Accuracy: 0.770

Precision (macro): 0.666

Recall (macro): 0.665

F1-score (macro): 0.665

ROC-AUC: 0.712

Confusion Matrix

TN = 1180

FP = 165

FN = 249

TP = 206

# Verificare CerinÈ›e Nivel 1

âœ” Accuracy â‰¥ 65% (0.77)
âœ” F1-score macro â‰¥ 0.60 (0.665)
âœ” Model salvat (.pt)
âœ” Evaluare realÄƒ pe test
âœ” UI integrat cu model antrenat

Integrare Ã®n UI (Streamlit)

Model Ã®ncÄƒrcat Ã®n:

models/trained_model.pt


Scaler Ã®ncÄƒrcat din:

scaler.pkl


InferenÈ›Äƒ realÄƒ:

logits = model(input_scaled)
prob = torch.sigmoid(logits)


UI afiÈ™eazÄƒ:

Probabilitate defect (%)

Decizie OK / DEFECT

RecomandÄƒri rule-based

Estimare km rÄƒmaÈ™i

Screenshot salvat Ã®n:

docs/screenshots/inference_real.png

# Nivel 2 â€“ Implementat

âœ” Early Stopping
âœ” Scheduler (ReduceLROnPlateau)
âœ” Prag decizie calibrat pe validation
âœ” Evaluare clarÄƒ TN/FP/FN/TP
âœ” Feature engineering realist (trend, stress, flags)

Indicatori Nivel 2

Accuracy = 0.77 (â‰¥ 0.75)

F1_macro = 0.665 (sub 0.70, dar peste prag minim)

AnalizÄƒ Erori (Context Industrial)
1. Clasele confundate

Majoritatea erorilor sunt:

False Negatives (FN = 249)
Defecte incipiente prezise OK.

CauzÄƒ:
Semnale borderline (presiune ulei 1.2â€“1.3 bar, temperaturi aproape normale).

2. Caracteristici problematice

Overlap Ã®ntre OK È™i Defect Ã®n zona presiune ulei marginalÄƒ.

Trend-uri absente dacÄƒ nu existÄƒ mÄƒsurare anterioarÄƒ.

Defecte incipiente greu separabile liniar.

3. Impact Industrial

False Negatives â†’ defect nedetectat â†’ risc mecanic.

False Positives â†’ alarmÄƒ falsÄƒ â†’ cost verificare suplimentar.

Strategie adoptatÄƒ:
Control FPR prin calibrare prag pe validation.

4. MÄƒsuri Corective Propuse

Introducere stare â€WATCHLISTâ€ pentru probabilitate 0.45â€“0.55.

CreÈ™terea ponderii trend_pressure Ã®n dataset.

Reducerea label noise pentru defecte incipiente.

PosibilÄƒ creÈ™tere max_fpr pentru recall mai mare.

# Structura FinalÄƒ Repository
Proiect_RN/
â”œâ”€â”€ data/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ trained_model.pt
â”œâ”€â”€ scaler.pkl
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_acquisition/
â”‚   â”œâ”€â”€ preprocesing/
â”‚   â”œâ”€â”€ neural_network/
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â”œâ”€â”€ train_model.py
â”‚   â”‚   â””â”€â”€ evaluare_model.py
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ app.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ screenshots/inference_real.png
â””â”€â”€ requirements.txt

# Checklist Final â€“ Etapa 5

âœ” Model antrenat de la zero
âœ” â‰¥10 epoci
âœ” Split 70/15/15 stratificat
âœ” Accuracy â‰¥65%
âœ” F1 macro â‰¥0.60
âœ” UI integrat cu model real
âœ” Confusion Matrix analizatÄƒ
âœ” Hiperparametri justificaÈ›i

# Concluzie Etapa 5

Modelul RN (MLP) a fost antrenat È™i evaluat cu succes pe un dataset realist OBD-like.

PerformanÈ›Äƒ obÈ›inutÄƒ:

Accuracy: 77%

F1 macro: 0.665

ROC-AUC: 0.712

Sistemul complet (Data â†’ Preprocess â†’ Train â†’ Eval â†’ UI) este funcÈ›ional È™i integrat.